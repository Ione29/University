{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a4a74dc-5958-4c8c-abdb-784135994d35",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b7f4d-d7d6-4a80-8288-b6eb5d76901c",
   "metadata": {},
   "source": [
    "## Assessment: Computer Vision for Industrial Inspection ##\n",
    "In this notebook, you will utilize what you've learned in this course to complete an assessment. The assessment has been divided into a couple of steps to guide your development. You will be graded based on the performance of your deep learning model. Note that this coding portion does not give partial credit - it shows up as either 0 or 60 points. \n",
    "<table border=\"1\" class=\"dataframe\" align='left'>  <thead>    <tr style=\"text-align: right;\">      <th>Step</th>      <th></th>      <th>Points</th>    </tr>  </thead>  <tbody>    <tr>      <td>0. The Problem</td>      <td></td>      <td></td>    </tr>    <tr>      <td>1. Data Curation</td>      <td></td>      <td></td>    </tr>    <tr>      <td>2. Prepare TAO Experiment</td>      <td></td>      <td></td>    </tr>    <tr>      <td>3. Model Training</td>      <td></td>      <td></td>    </tr>    <tr>      <td>4. Model Evaluation</td>      <td></td>      <td>60</td>    </tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c1a85-e36c-4396-93fb-524048c66684",
   "metadata": {},
   "source": [
    "<p><img src='images/ml_workflow.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e4be02-6163-4282-ad82-892dee6d17a0",
   "metadata": {},
   "source": [
    "### Step 0: The Problem ###\n",
    "In this course, we made a binary classifier for the true/false defective units in our printed circuit board assembly dataset. For the asssesment we are asking you to create a model over the same dataset, but with a different purpose. Before we dealt with `capacitors` only, but the reference circuit boards have other components as well. In particular, we are interested in classifying the following four components based on their images: \n",
    "\n",
    "<p><img src='images/assessment_samples.png' width=720></p>\n",
    "\n",
    "The component types are marked by the first letter(s) of component identification numbers. \n",
    "* **C** - Capacitor\n",
    "* **Q** - Transistor\n",
    "* **R** - Resistor\n",
    "* **U** - Integrated Circuit\n",
    "\n",
    "Your task is to train and evaluate a classifier that accurately labels the four component types. We recommend using `VGG19` as the architecture in the spirit of experimenting with different backbones. \n",
    "\n",
    "**Instructions**: <br> \n",
    "0.1 Execute the below cell to import dependencies <br>\n",
    "0.2 Execute the cell below to unzip and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6854c3b3-4640-4b5d-99dd-df66f1bb6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# import dependencies\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import shutil\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c9a2e4-9e8a-4031-b955-14a5c2f16f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open data/viz_BYD_new.zip, data/viz_BYD_new.zip.zip or data/viz_BYD_new.zip.ZIP.\n",
      "rm: cannot remove 'data/viz_BYD_new.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 0.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# unzip\n",
    "!unzip -qq data/viz_BYD_new.zip -d data\n",
    "\n",
    "# remove zip file\n",
    "!rm data/viz_BYD_new.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27c9b9-b8f9-4331-b6dd-f3a1c7da2058",
   "metadata": {},
   "source": [
    "### Step 1: Data Curation ###\n",
    "The first step is to curate the data. \n",
    "\n",
    "**Instructions**: <br>\n",
    "1.1 Execute the below cell to load the data into a `DataFrame` and preview. <br>\n",
    "1.2 Modify the `<FIXME>` only and execute the cell below to filter and keep only normal images as potential defective images may include missing parts. <br>\n",
    "1.3 Modify the `<FIXME>` only and execute the cell below to filter and keep only relevant images, i.e. `C`, `Q`, `R`, or `U`. <br>\n",
    "1.4 Execute the cell below to check the sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47f1a7e0-ed48-4378-8ddb-56d9ef8a1357",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pcba_df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 1.1\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DO NOT CHANGE THIS CELL\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# load from pcba_df.csv\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m pcba_df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpcba_df.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m pcba_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pcba_df.csv'"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# load from pcba_df.csv\n",
    "pcba_df=pd.read_csv('pcba_df.csv')\n",
    "pcba_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1831b93c-deb5-40c6-a55b-4feb22c568fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2\n",
    "verified_df=pcba_df[pcba_df['true_defect']=='notdefect']\n",
    "verified_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb4e9ed-2d53-4d79-b67e-9e6da8fe2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "cqru_df=verified_df[verified_df['comp_type'].isin(['C', 'Q', 'R', 'U'])]\n",
    "cqru_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa67e90e-876c-4280-81d6-13452b6bae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# check sample size\n",
    "cqru_df.groupby('comp_type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c569654d-7fe0-4af4-b8ea-d2326bb684a2",
   "metadata": {},
   "source": [
    "### Step 2: Prepare TAO Experiment ###\n",
    "Next we will prepare for the TAO experiment. \n",
    "\n",
    "**Instructions**: <br>\n",
    "2.1 Execute the below cell to set environment variables. <br>\n",
    "2.2 Execute the cell below to map up local directories to the TAO docker. <br>\n",
    "2.3 Execute the cell below to use the `ngc registry mode list` command that lists all available `classification` models. <br>\n",
    "2.4 Modify the `<FIXME>` only and execute the cell below to download the `VGG19` pre-trained weights. <br>\n",
    "2.5 Execute the cell below to view the pre-trained model. <br>\n",
    "2.6 Execute the cell below to create the required data directories. <br>\n",
    "2.7 Execute the cell below to create a 70%/30% split for train and val. <br>\n",
    "2.8 Execute the cell below to copy data from the source to the TAO experiment folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55f23d5-5509-4a22-8d8b-b2c9612d75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# set environment variables\n",
    "%set_env KEY=my_model_key\n",
    "\n",
    "%set_env LOCAL_PROJECT_DIR=/dli/task/tao_project\n",
    "%set_env LOCAL_DATA_DIR=/dli/task/tao_project/data\n",
    "%set_env LOCAL_SPECS_DIR=/dli/task/tao_project/spec_files\n",
    "os.environ[\"LOCAL_EXPERIMENT_DIR\"]=os.path.join(os.getenv(\"LOCAL_PROJECT_DIR\"), \"classification\")\n",
    "\n",
    "%set_env TAO_PROJECT_DIR=/workspace/tao-experiments\n",
    "%set_env TAO_DATA_DIR=/workspace/tao-experiments/data\n",
    "%set_env TAO_SPECS_DIR=/workspace/tao-experiments/spec_files\n",
    "os.environ['TAO_EXPERIMENT_DIR']=os.path.join(os.getenv(\"TAO_PROJECT_DIR\"), \"classification\")\n",
    "\n",
    "# make the data directory\n",
    "!mkdir -p $LOCAL_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a6cbe-430d-4c54-8897-64aa5d41a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# map local directories to the TAO docker\n",
    "mounts_file = os.path.expanduser(\"~/.tao_mounts.json\")\n",
    "\n",
    "drive_map = {\n",
    "    \"Mounts\": [\n",
    "            # Mapping the data directory\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_PROJECT_DIR\"],\n",
    "                \"destination\": \"/workspace/tao-experiments\"\n",
    "            },\n",
    "            # Mapping the specs directory.\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_SPECS_DIR\"],\n",
    "                \"destination\": os.environ[\"TAO_SPECS_DIR\"]\n",
    "            },\n",
    "            # Mapping the data directory.\n",
    "            {\n",
    "                \"source\": os.environ[\"LOCAL_DATA_DIR\"],\n",
    "                \"destination\": os.environ[\"TAO_DATA_DIR\"]\n",
    "            },\n",
    "        ],\n",
    "    \"DockerOptions\": {\n",
    "        \"user\": \"{}:{}\".format(os.getuid(), os.getgid())\n",
    "    }\n",
    "}\n",
    "\n",
    "# writing the mounts file\n",
    "with open(mounts_file, \"w\") as mfile:\n",
    "    json.dump(drive_map, mfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebc8c2a-bb02-4515-8923-1cb6f53b2bef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.3\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!ngc registry model list nvidia/tao/pretrained_classification:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548bd5b4-0e54-48f7-82d1-549623cd92db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.4\n",
    "# create directory to store the pre-trained model\n",
    "!mkdir -p $LOCAL_EXPERIMENT_DIR/pretrained_vgg19/\n",
    "\n",
    "# download the pre-trained vgg19 model from NGC\n",
    "!ngc registry model download-version nvidia/tao/pretrained_classification:vgg19 --dest $LOCAL_EXPERIMENT_DIR/pretrained_vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc0cf5-4c9d-476e-a302-6a175fc04d3a",
   "metadata": {},
   "source": [
    "<p><img src='images/tip.png' width=720></p>\n",
    "\n",
    "We designated the model to be downloaded to `tao_project/classification/pretrained_vgg19`, which is mapped to `/workspace/tao-experiments/classification/pretrained_vgg19` in the TAO container based on the mapping of `LOCAL_EXPERIMENT_DIR` to `TAO_EXPERIMENT_DIR`. Looking at the `local_path` and `transfer_id` keys of the output JSON, we can gather that the path of the pre-trained model should be in the `tao_project/classification/pretrained_vgg19/pretrained_classification_vvgg19` directory. When referencing paths for the TAO Toolkit, it's important to use paths based on the TAO container. In this case it would be `/workspace/tao-experiments/classification/pretrained_vgg19/pretrained_classification_vvgg19`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7655abf-8c17-4c85-86cb-8f594e932f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!ls -al tao_project/classification/pretrained_vgg19/pretrained_classification_vvgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2538dd6b-51bb-4347-b48b-fe1c1ee69dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# remove existing data from previous experiment (if any)\n",
    "!rm -rf $LOCAL_DATA_DIR/*\n",
    "\n",
    "!mkdir -p $LOCAL_DATA_DIR/train/Q\n",
    "!mkdir -p $LOCAL_DATA_DIR/train/C\n",
    "!mkdir -p $LOCAL_DATA_DIR/train/U\n",
    "!mkdir -p $LOCAL_DATA_DIR/train/R\n",
    "!mkdir -p $LOCAL_DATA_DIR/val/Q\n",
    "!mkdir -p $LOCAL_DATA_DIR/val/C\n",
    "!mkdir -p $LOCAL_DATA_DIR/val/U\n",
    "!mkdir -p $LOCAL_DATA_DIR/val/R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1521c5f5-3f0c-461e-a561-664dc68d8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# set default as training set\n",
    "cqru_df['data_set']='train'\n",
    "\n",
    "# sample 30% and set as validation set\n",
    "val_set=cqru_df.groupby('comp_type', group_keys=False).apply(lambda x: x.sample(frac=0.3))\n",
    "cqru_df.loc[val_set.index, 'data_set']='val'\n",
    "cqru_df.groupby(['data_set', 'comp_type']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f67e2b-0b15-4264-bc71-f08423236ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# iterate through the DataFrame and copy images\n",
    "for idx, row in cqru_df.iterrows(): \n",
    "    shutil.copyfile(row['defect_img_path'], f\"{os.environ['LOCAL_DATA_DIR']}/{row['data_set']}/{row['comp_type']}/{row['date']}_{row['board']}_{row['defect_image_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455daecb-fbd1-4e1e-a831-68b4672f10ed",
   "metadata": {},
   "source": [
    "### Step 3: Model Training ###\n",
    "The next step is to modify the configuration file that will be used for `train`. You can create a new text file for this purpose manually and start from scratch or use the [template provided](tao_project/spec_files/vgg19/config.txt). You can also refer to sample applications and configuration files [here](https://docs.nvidia.com/tao/tao-toolkit/text/image_classification.html). \n",
    "\n",
    "**Instructions**: <br>\n",
    "3.1. Open and review the [configuration file](tao_project/spec_files/vgg19/config.txt). <br>\n",
    "3.2. Modify the `<FIXME>`s only in the configuration file with the correct values and **save changes**. We recommend starting with a very low epoch count (e.g. 5) in the interest of time as each epoch can take ~100s to complete. <br>\n",
    "* Recall that you don't need the `eval_config` section of the configuration file, which requires you to know the trained model path. Of course, if you know where you would like to place the model, you can go ahead and complete this section. \n",
    "3.3 Execute the cell below to initiate model training. \n",
    "\n",
    "<p><img src='images/tip.png' width=720></p>\n",
    "\n",
    "Based on how NGC names the pre-trained model downloaded, we should use `/workspace/tao-experiments/classification/pretrained_vgg19/pretrained_classification_vvgg19/resnet_19.hdf5` to reference the pre-trained model. Furthermore, we can choose where to store the trained model - in this case we use `/workspace/tao-experiments/classification/vgg19` inside of the TAO container, which is mapped to `tao_project/classification/vgg19` in our local drive. Furthermore, the trained model name will follow the format `<model_arch>_0<last_epoch_count>.tlt`, unless specified otherwise. Therefore we should use `/workspace/tao-experiments/classification/vgg19/weights/vgg_XXX.tlt`, depending on `n_epochs` in the model configuration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fba5b6-ee35-48ab-9f09-6608c9388685",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# train model\n",
    "!tao model classification_tf1 train -e $TAO_SPECS_DIR/vgg19/config.txt \\\n",
    "                                   -r $TAO_EXPERIMENT_DIR/vgg19 \\\n",
    "                                   -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d92840-c3cd-4b9a-b025-c47d1bbb2f32",
   "metadata": {},
   "source": [
    "### Step 4: Model Evaluation ###\n",
    "The last step for the assessment is to `evaluate` the model through the `eval_config` section of the configuration file. Once completed, you should submit the output log for assessment. \n",
    "\n",
    "**Instructions**: <br>\n",
    "4.1 Review the [configuration file](tao_project/spec_files/vgg19/config.txt) and modify the `eval_config` section if needed. <br>\n",
    "4.2 Execute the below cell to evaluate the model. A log file will be generated through the use of the `--log_file` option, which will be used for grading purposes. <br>\n",
    "4.3 Execute the cell below to submit the log for assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637cba7-5394-4671-b6c9-49df0ff7303d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "# evaluate the model using the same validation set as training\n",
    "!tao model classification_tf1 evaluate -e $TAO_SPECS_DIR/vgg19/config.txt\\\n",
    "                                       -k $KEY \\\n",
    "                                       --log_file $TAO_PROJECT_DIR/log_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5384a9ac-c05b-4179-940a-9fdfab23337e",
   "metadata": {},
   "source": [
    "Click [here](tao_project/log_file.txt) to view the log file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a796eaf-3086-48fa-b18c-7d227ad410c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!cp $LOCAL_PROJECT_DIR/log_file.txt my_assessment/log_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab7921b-734c-4cb1-8b91-7ab1b00892cb",
   "metadata": {},
   "source": [
    "### Grade Your Code ###\n",
    "If you have trained the model and completed model evaluation successfully, save changes to the notebook and revisit the webpage where you launched this interactive environment. Click on the \"**ASSESS TASK**\" button as shown in the screenshot below. Doing so will give you credit for this part of the lab that counts towards earning a certificate of competency for the entire course.\n",
    "<p><img src='images/credit.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e13c81-abd4-43a2-bfe8-774116b3257f",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
